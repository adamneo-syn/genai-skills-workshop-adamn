{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## AIM OF THE FOLLOWING APP"
      ],
      "metadata": {
        "id": "g9yg9gV-xg3V"
      },
      "id": "g9yg9gV-xg3V"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The app that we will be creating in this notebook will answer questions about the Alaska Department of Snow, or questions about how much snowfall is expected in Alaska on the current day."
      ],
      "metadata": {
        "id": "vUqj27pNxku5"
      },
      "id": "vUqj27pNxku5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DOWNLOADING THE NECESSARY PACKAGES"
      ],
      "metadata": {
        "id": "bZFOKfQ_xwwF"
      },
      "id": "bZFOKfQ_xwwF"
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet google-genai"
      ],
      "metadata": {
        "id": "RCiBuFUiUWJl"
      },
      "id": "RCiBuFUiUWJl",
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet ipytest"
      ],
      "metadata": {
        "id": "SySCKD-2XRKt"
      },
      "id": "SySCKD-2XRKt",
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from IPython.display import Markdown, display\n",
        "from google import genai\n",
        "from google.genai.types import GenerateContentConfig\n",
        "from google.genai import types"
      ],
      "metadata": {
        "id": "FL3z92KuUZww"
      },
      "id": "FL3z92KuUZww",
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SETTING UP THE BIGQUERY TABLE THAT WILL COMPRISE OUR RAG"
      ],
      "metadata": {
        "id": "OpSRZsQv6o19"
      },
      "id": "OpSRZsQv6o19"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the data from the gcloud storage into the environment, and loading it into a dataframe"
      ],
      "metadata": {
        "id": "xBvT7QW1C4Lf"
      },
      "id": "xBvT7QW1C4Lf"
    },
    {
      "cell_type": "code",
      "id": "AQyxGzxepAYFUDTTypQO318N",
      "metadata": {
        "tags": [],
        "id": "AQyxGzxepAYFUDTTypQO318N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bc058ef-7f48-4aa7-807f-a342854a6a9a"
      },
      "source": [
        "!gsutil cp gs://labs.roitraining.com/alaska-dept-of-snow/* ."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/.DS_Store...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/alaska-dept-of-snow-faqs.csv...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-01.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-02.txt...\n",
            "- [4 files][ 16.2 KiB/ 16.2 KiB]                                                \n",
            "==> NOTE: You are performing a sequence of gsutil operations that may\n",
            "run significantly faster if you instead use gsutil -m cp ... Please\n",
            "see the -m section under \"gsutil help options\" for further information\n",
            "about when gsutil -m can be advantageous.\n",
            "\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-03.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-04.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-05.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-06.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-07.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-08.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-09.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-10.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-11.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-12.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-13.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-14.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-15.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-16.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-17.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-18.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-19.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-20.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-21.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-22.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-23.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-24.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-25.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-26.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-27.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-28.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-29.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-30.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-31.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-32.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-33.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-34.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-35.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-36.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-37.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-38.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-39.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-40.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-41.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-42.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-43.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-44.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-45.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-46.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-47.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-48.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-49.txt...\n",
            "Copying gs://labs.roitraining.com/alaska-dept-of-snow/faq-50.txt...\n",
            "/ [52 files][ 25.4 KiB/ 25.4 KiB]                                               \n",
            "==> NOTE: You are performing a sequence of gsutil operations that may\n",
            "run significantly faster if you instead use gsutil -m cp ... Please\n",
            "see the -m section under \"gsutil help options\" for further information\n",
            "about when gsutil -m can be advantageous.\n",
            "\n",
            "\n",
            "Operation completed over 52 objects/25.4 KiB.                                    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iH9souUvG7Hs",
        "outputId": "473987be-6f63-46da-cd78-8b3f739dded1"
      },
      "id": "iH9souUvG7Hs",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alaska-dept-of-snow-faqs.csv  faq-09.txt  faq-18.txt  faq-27.txt  faq-36.txt  faq-45.txt\n",
            "faq-01.txt\t\t      faq-10.txt  faq-19.txt  faq-28.txt  faq-37.txt  faq-46.txt\n",
            "faq-02.txt\t\t      faq-11.txt  faq-20.txt  faq-29.txt  faq-38.txt  faq-47.txt\n",
            "faq-03.txt\t\t      faq-12.txt  faq-21.txt  faq-30.txt  faq-39.txt  faq-48.txt\n",
            "faq-04.txt\t\t      faq-13.txt  faq-22.txt  faq-31.txt  faq-40.txt  faq-49.txt\n",
            "faq-05.txt\t\t      faq-14.txt  faq-23.txt  faq-32.txt  faq-41.txt  faq-50.txt\n",
            "faq-06.txt\t\t      faq-15.txt  faq-24.txt  faq-33.txt  faq-42.txt\n",
            "faq-07.txt\t\t      faq-16.txt  faq-25.txt  faq-34.txt  faq-43.txt\n",
            "faq-08.txt\t\t      faq-17.txt  faq-26.txt  faq-35.txt  faq-44.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting the list of files that we will want to process for our RAG. It is assumed here that we only want the txt files"
      ],
      "metadata": {
        "id": "D0bq37YZIYBq"
      },
      "id": "D0bq37YZIYBq"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "relevant_files = []\n",
        "\n",
        "for file in os.listdir():\n",
        "  if \"faq-\" in file:\n",
        "    relevant_files.append(file)"
      ],
      "metadata": {
        "id": "VF5v-_EXICr8"
      },
      "id": "VF5v-_EXICr8",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now load the files into a pandas dataframe, which we will subsequently use to create a Bigquery dataframe"
      ],
      "metadata": {
        "id": "QEeFUNZYI83F"
      },
      "id": "QEeFUNZYI83F"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "preload_list = []\n",
        "\n",
        "for file in relevant_files:\n",
        "  f = open(file)\n",
        "  raw_data = [row.strip('\\n') for row in f.readlines()]\n",
        "  raw_diction = {\"question\":raw_data[0],\"answer\":raw_data[2]}\n",
        "  # Loading the dictionary into the list that will be used to create our pandas dataframe\n",
        "  preload_list.append(raw_diction)\n",
        "  f.close()\n",
        "\n",
        "rag_pandas = pd.DataFrame(preload_list)"
      ],
      "metadata": {
        "id": "Ok34k3KfJNVl"
      },
      "id": "Ok34k3KfJNVl",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now load our pandas dataframe into Bigquery. For the purpose of this exercise, we assume this is a one-off setup"
      ],
      "metadata": {
        "id": "rsjEDivWKhbo"
      },
      "id": "rsjEDivWKhbo"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas_gbq\n",
        "\n",
        "project_id =\"qwiklabs-gcp-02-cf6490c204fb\"\n",
        "table_id = \"RAG.ads_questions_raw\"\n",
        "\n",
        "pandas_gbq.to_gbq(rag_pandas, table_id, project_id=project_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daVbvrPVKkow",
        "outputId": "bd4b7b6b-aff3-46c8-eec4-c77f7f5fdd01"
      },
      "id": "daVbvrPVKkow",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 9058.97it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CREATING OUR VECTOR DATABASE IN BIGQUERY"
      ],
      "metadata": {
        "id": "SkJiv5V1LYts"
      },
      "id": "SkJiv5V1LYts"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We begin by defining our model that we will use for the vector search. Here, it is assumed that is a one-off setup"
      ],
      "metadata": {
        "id": "0sj0yhM1Lo-H"
      },
      "id": "0sj0yhM1Lo-H"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "bq_client = bigquery.Client(project=project_id)\n",
        "\n",
        "query = \"\"\"CREATE OR REPLACE MODEL `RAG.embedding_model`\n",
        "REMOTE WITH CONNECTION `us.rag_embeddings`\n",
        "OPTIONS (ENDPOINT = 'text-embedding-005');\n",
        "\"\"\"\n",
        "\n",
        "query_job = bq_client.query(query)\n",
        "query_job.result()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9QKBZxBLc6o",
        "outputId": "23f40f93-042a-4ccb-eecf-eecc90f565b1"
      },
      "id": "b9QKBZxBLc6o",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<google.cloud.bigquery.table._EmptyRowIterator at 0x7e82cfb94280>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now create the embeddings table that will act as our data store for the RAG"
      ],
      "metadata": {
        "id": "Wv1csQETL9EF"
      },
      "id": "Wv1csQETL9EF"
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "CREATE OR REPLACE TABLE `qwiklabs-gcp-02-cf6490c204fb.RAG.ads_questions_embeddings` AS\n",
        "SELECT *\n",
        "FROM ML.GENERATE_EMBEDDING(\n",
        "    MODEL `RAG.embedding_model`,\n",
        "    (SELECT question, answer, concat('Q: ',question, ' A: ',answer) AS content FROM `qwiklabs-gcp-02-cf6490c204fb.RAG.ads_questions_raw`)\n",
        ");\n",
        "\"\"\"\n",
        "query_job = bq_client.query(query)\n",
        "query_job.result()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucD819zcL3cp",
        "outputId": "9d84a66d-1657-4f63-cbb5-e744c6457669"
      },
      "id": "ucD819zcL3cp",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<google.cloud.bigquery.table._EmptyRowIterator at 0x7e82984cf580>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We run the query below as a means of demonstrating what our vector database looks like"
      ],
      "metadata": {
        "id": "mgz5Q1WS4tnL"
      },
      "id": "mgz5Q1WS4tnL"
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "  SELECT base.question as question, base.answer as answer, distance\n",
        "FROM VECTOR_SEARCH(\n",
        "  TABLE `RAG.ads_questions_embeddings`, 'ml_generate_embedding_result',\n",
        "  (\n",
        "  SELECT text_embedding, content AS query\n",
        "  FROM ML.GENERATE_TEXT_EMBEDDING(\n",
        "  MODEL `RAG.embedding_model`,\n",
        "  (SELECT 'What is the ADS?' AS content))\n",
        "  ),\n",
        "  top_k => 3, options => '{\"fraction_lists_to_search\": 0.01}')\n",
        "  ;\n",
        "\"\"\"\n",
        "query_job = bq_client.query(query)\n",
        "rows = query_job.result()\n",
        "\n",
        "for row in rows:\n",
        "    print(row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FK_TuPIe40oO",
        "outputId": "8af19250-4d31-42b2-e2c9-08efa7e08236"
      },
      "id": "FK_TuPIe40oO",
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row(('How can I stay informed about ADS news and updates?', 'Subscribe to the ADS newsletter on the official website or follow the department’s social media channels for ongoing updates and announcements.', 0.8017229427683615), {'question': 0, 'answer': 1, 'distance': 2})\n",
            "Row(('Who is the CFO of ADS?', 'The current CFO is Janet Kirk, appointed in 2022. She oversees all financial operations, including cost management and budget forecasting.', 0.8274179311401391), {'question': 0, 'answer': 1, 'distance': 2})\n",
            "Row(('How does ADS handle interagency communication?', 'ADS uses a centralized coordination system shared with local governments, school districts, and emergency services to streamline announcements and responses.', 0.8417617752076187), {'question': 0, 'answer': 1, 'distance': 2})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ACCESSING API FOR FURTHER BACKEND FUNCTIONALITY"
      ],
      "metadata": {
        "id": "DKeb5fJADexu"
      },
      "id": "DKeb5fJADexu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we define a function that will leverage Vertex AI's Tool and FunctionDeclaration, along with https://api.weather.gov, to determine how much snow is expected in Alaska on a given day"
      ],
      "metadata": {
        "id": "k0XeC-fro4KA"
      },
      "id": "k0XeC-fro4KA"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_snowfall_info():\n",
        "\n",
        "  # Importing the necessary packages\n",
        "  import vertexai\n",
        "  from vertexai.generative_models import (\n",
        "    Content,\n",
        "    FunctionDeclaration,\n",
        "    GenerationConfig,\n",
        "    GenerativeModel,\n",
        "    Part,\n",
        "    Tool,\n",
        "    ToolConfig\n",
        "  )\n",
        "\n",
        "  project_id =\"qwiklabs-gcp-02-cf6490c204fb\"\n",
        "  location=\"us-central1\"\n",
        "  model_name = \"gemini-2.5-pro-preview-05-06\"\n",
        "\n",
        "  # Initialising the Gemini Model\n",
        "  gemini_model = GenerativeModel(model_name = model_name)\n",
        "\n",
        "  # Defining our FunctionDeclaration\n",
        "  get_snow_func = FunctionDeclaration(\n",
        "      name = \"get_snowfall\",\n",
        "      description = \"Get the expected snowfall in Alaska\",\n",
        "      parameters = {\n",
        "          \"type\":\"object\",\n",
        "          \"properties\": {\n",
        "              \"location\": {\n",
        "                  \"type\":\"string\",\n",
        "                  \"description\": \"The city name of the location for which to get the weather.\",\n",
        "                  \"default\": {\n",
        "                      \"string_value\": \"Anchorage, AK\"\n",
        "                  }\n",
        "              }\n",
        "          }\n",
        "      }\n",
        "  )\n",
        "\n",
        "  # Defining the base prompt\n",
        "  user_promp_content = Content(\n",
        "      role = \"user\",\n",
        "      parts = [\n",
        "          Part.from_text(\"How much snow is expected to fall in Alaska today?\")\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  # Defining our tool\n",
        "  tool = Tool(function_declarations=[get_snow_func])\n",
        "\n",
        "  # Getting our initial response\n",
        "  initial_response =gemini_model.generate_content(\n",
        "    user_prompt_content,\n",
        "    generation_config=GenerationConfig(temperature=0),\n",
        "    tools=[tool],\n",
        "    tool_config=ToolConfig(\n",
        "        function_calling_config=ToolConfig.FunctionCallingConfig(\n",
        "            # ANY mode forces the model to predict only function calls\n",
        "            mode=ToolConfig.FunctionCallingConfig.Mode.ANY,\n",
        "            # Allowed function calls to predict when the mode is ANY. If empty, any  of\n",
        "            # the provided function calls will be predicted.\n",
        "            allowed_function_names=[\"get_snowfall\"],\n",
        "        )\n",
        "    )\n",
        ")\n",
        "\n",
        "  # Getting the API responses that the model will reference against.\n",
        "  lat, lon = 61.2174, -149.8631  # Fixing this to Mount Mackenzie, Alaska for\n",
        "\n",
        "  headers = {\n",
        "      'User-Agent':'email',\n",
        "      'Accept':'application/ld+json'\n",
        "  }\n",
        "\n",
        "  point_url = f'https://api.weather.gov/points/{lat},{lon}'\n",
        "\n",
        "  point_response = requests.get(point_url, headers=headers)\n",
        "  forecast_url = point_response.json()['forecast']\n",
        "  forecast_response = requests.get(forecast_url, headers=headers)\n",
        "  api_response = forecast_response.json()\n",
        "\n",
        "  # Retrieving our response that also includes info from the weather api\n",
        "  final_response = gemini_model.generate_content(\n",
        "      [\n",
        "          user_prompt_content,  # User prompt\n",
        "          initial_response.candidates[0].content,  # Function call response\n",
        "          Content(\n",
        "              parts=[\n",
        "                  Part.from_function_response(\n",
        "                      name=\"get_snowfall\",\n",
        "                      response={\n",
        "                          \"content\": api_response,  # Return the API response to Gemini\n",
        "                      },\n",
        "                  )\n",
        "              ],\n",
        "          ),\n",
        "      ],\n",
        "      tools=[tool],\n",
        "  )\n",
        "  # Get the model summary response\n",
        "  summary = final_response.text\n",
        "\n",
        "  return summary"
      ],
      "metadata": {
        "id": "gHjp8UEAnWbC"
      },
      "id": "gHjp8UEAnWbC",
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_snowfall_info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "AKYJMKKwq3-n",
        "outputId": "53bbdbc4-0213-43fe-b974-f9b3a09ce00a"
      },
      "id": "AKYJMKKwq3-n",
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'It looks like there is no snow expected in Anchorage, Alaska today. The forecast is mostly sunny with a high near 52 degrees Fahrenheit.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DEFINING OUR RAG FUNCTIONS"
      ],
      "metadata": {
        "id": "_22LF7iHGA-G"
      },
      "id": "_22LF7iHGA-G"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below functions perform embedding comparisons between a question and what is available within the vector database. It should also be noted that we have set this up to only apply examples with a minimum similarity score, to minimise irrelevant examples being applied to the prompt."
      ],
      "metadata": {
        "id": "2tAQ4Zh55Z_P"
      },
      "id": "2tAQ4Zh55Z_P"
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_bq_search(client,question,k):\n",
        "  # Defining our base query\n",
        "  base_query = \"\"\"\n",
        "  SELECT base.content, distance\n",
        "FROM VECTOR_SEARCH(\n",
        "  TABLE `RAG.ads_questions_embeddings`, 'ml_generate_embedding_result',\n",
        "  (\n",
        "  SELECT text_embedding, content AS query\n",
        "  FROM ML.GENERATE_TEXT_EMBEDDING(\n",
        "  MODEL `RAG.embedding_model`,\n",
        "  (SELECT '{}' AS content))\n",
        "  ),\n",
        "  top_k => {}, options => '{{\"fraction_lists_to_search\": 0.01}}')\n",
        "  \"\"\"\n",
        "  # customised query to the user's question.\n",
        "  customised_query = base_query.format(question, k)\n",
        "\n",
        "  query_job = client.query(customised_query)\n",
        "  output = []\n",
        "  for row in query_job:\n",
        "    output.append({\"content\":row.content,\"similarity\":row.distance})\n",
        "\n",
        "  return output"
      ],
      "metadata": {
        "id": "URii3IQ7GHCs"
      },
      "id": "URii3IQ7GHCs",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_prompt_with_examples(question, example_list,min_similarity):\n",
        "\n",
        "  relevant_examples = \"\"\n",
        "\n",
        "  # Only apply RAG entries that exceed the minimum similarity threshold\n",
        "  for entry in example_list:\n",
        "    example = entry[\"content\"]\n",
        "    similarity_score = entry[\"similarity\"]\n",
        "\n",
        "    if similarity_score > min_similarity:\n",
        "      relevant_examples += example + '\\n'\n",
        "\n",
        "  # return prompt based on the presence of valid RAG examples\n",
        "  if len(relevant_examples) > 0:\n",
        "    prompt = f\"\"\"\n",
        "    Instructions: Answer the following question using the provided context.\n",
        "\n",
        "    Question: {question}\n",
        "\n",
        "    Context: {relevant_examples}\n",
        "    \"\"\"\n",
        "  else:\n",
        "    prompt = f\"\"\"\n",
        "    Instructions: Answer the following question .\n",
        "\n",
        "    Question: {question}\n",
        "    \"\"\"\n",
        "\n",
        "  return prompt"
      ],
      "metadata": {
        "id": "itai0YvyGMEU"
      },
      "id": "itai0YvyGMEU",
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing our RAG retrieval setup. Here, we can see that the prompt only has examples applied if they meet the minimum threshold. If not, the generic question will be input to the genai model"
      ],
      "metadata": {
        "id": "c-hK5o3V5wAf"
      },
      "id": "c-hK5o3V5wAf"
    },
    {
      "cell_type": "code",
      "source": [
        "test_out = perform_bq_search(bq_client,\"what is the ads and what do they do?\",3)\n",
        "\n",
        "build_prompt_with_examples(\"what is the ads and what do they do?\", test_out, 0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "GpNwtQRlSC5o",
        "outputId": "e25a8c1d-6763-4bbf-e7d6-a49c69df5de0"
      },
      "id": "GpNwtQRlSC5o",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n    Instructions: Answer the following question using the provided context.\\n    \\n    Question: what is the ads and what do they do?\\n\\n    Context: Q: How can I stay informed about ADS news and updates? A: Subscribe to the ADS newsletter on the official website or follow the department’s social media channels for ongoing updates and announcements.\\nQ: Who is the CFO of ADS? A: The current CFO is Janet Kirk, appointed in 2022. She oversees all financial operations, including cost management and budget forecasting.\\nQ: What concerns does the CFO have about ADS operations? A: The CFO is primarily concerned about controlling operational costs, especially regarding cloud-based technology solutions for data management.\\n\\n    '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_out = perform_bq_search(bq_client,\"what is the ads and what do they do?\",3)\n",
        "\n",
        "build_prompt_with_examples(\"what is the ads and what do they do?\", test_out, 0.96)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Y5_B0YteSWP4",
        "outputId": "d98b4f7c-e73e-4ed8-e28e-f6bf660d93c1"
      },
      "id": "Y5_B0YteSWP4",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n    Instructions: Answer the following question .\\n    \\n    Question: what is the ads and what do they do?\\n    '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HANDLING SECURITY FOR THE PROMPTS"
      ],
      "metadata": {
        "id": "aOB0LnQ06W67"
      },
      "id": "aOB0LnQ06W67"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below handles prompt security for our setup"
      ],
      "metadata": {
        "id": "U0hKe0Sk5_K1"
      },
      "id": "U0hKe0Sk5_K1"
    },
    {
      "cell_type": "code",
      "source": [
        "safety_settings = [types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_HATE_SPEECH\",\n",
        "      threshold=\"BLOCK_LOW_AND_ABOVE\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "      threshold=\"BLOCK_LOW_AND_ABOVE\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "      threshold=\"BLOCK_LOW_AND_ABOVE\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_HARASSMENT\",\n",
        "      threshold=\"BLOCK_LOW_AND_ABOVE\"\n",
        "    )]"
      ],
      "metadata": {
        "id": "xVNw9g5Q6mWF"
      },
      "id": "xVNw9g5Q6mWF",
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_instruction_context = \"\"\"\n",
        "You are a customer facing AI chatbot.\n",
        "Your mission is to provide answers about the Alaska Department of Snow, or ADS for short.\n",
        "Remember that before you answer a question, you must check to see if it complies with your mission.\n",
        "If not, you can say Sorry, I can't answer that question.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "AD57yvZtSVXm"
      },
      "id": "AD57yvZtSVXm",
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def define_config(client, system_instructions, safety, temp, top_p, tokens):\n",
        "\n",
        "  generated_config = types.GenerateContentConfig(\n",
        "    temperature = temp,\n",
        "    top_p = top_p,\n",
        "    max_output_tokens = tokens,\n",
        "    response_modalities = [\"TEXT\"],\n",
        "    safety_settings = safety,\n",
        "    system_instruction=[types.Part.from_text(text=system_instructions)],\n",
        "  )\n",
        "\n",
        "  return generated_config\n"
      ],
      "metadata": {
        "id": "i8U5a71NUNj6"
      },
      "id": "i8U5a71NUNj6",
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now create a config that is based on our security settings"
      ],
      "metadata": {
        "id": "pWF8FGu2Ulo0"
      },
      "id": "pWF8FGu2Ulo0"
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining our filters for our prompt. Here we set temperature to a low value, to ensure consistency in the responses.\n",
        "top_p = 0.95\n",
        "temperature = 0.1\n",
        "max_output_tokens = 8192\n",
        "\n",
        "client = genai.Client(\n",
        "      vertexai=True,\n",
        "      project=\"qwiklabs-gcp-02-cf6490c204fb\",\n",
        "      location=\"us-central1\",\n",
        ")\n",
        "\n",
        "# Generating our config for the Gen AI Setup\n",
        "generated_content_config = define_config(client, system_instruction_context, safety_settings, temperature, top_p, max_output_tokens)"
      ],
      "metadata": {
        "id": "S9vjUT8_UqIG"
      },
      "id": "S9vjUT8_UqIG",
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FUNCTION TO APPLY OUR RAG SETUP"
      ],
      "metadata": {
        "id": "xav63jh0GTh0"
      },
      "id": "xav63jh0GTh0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below method will leverage the RAG setup that we had specified"
      ],
      "metadata": {
        "id": "B-d6M1qr6GiU"
      },
      "id": "B-d6M1qr6GiU"
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_rag(project,location,model,config,question,k,similarity_score):\n",
        "\n",
        "  from google import genai\n",
        "  from google.genai.types import GenerateContentConfig\n",
        "  from google.genai import types\n",
        "\n",
        "  client = genai.Client(\n",
        "      vertexai=True,\n",
        "      project=project,\n",
        "      location=location,\n",
        "  )\n",
        "\n",
        "  bq_client = bigquery.Client(project=project_id)\n",
        "\n",
        "  # Defining our closes matches from BQ\n",
        "  rag_matches = perform_bq_search(bq_client,question,k)\n",
        "\n",
        "  # Defining our prompt with the RAG outputs\n",
        "  rag_ammended_prompt = build_prompt_with_examples(question, rag_matches,similarity_score)\n",
        "\n",
        "  # Getting our response\n",
        "  chat = client.chats.create(model=model,config=config)\n",
        "  response = chat.send_message(rag_ammended_prompt)\n",
        "\n",
        "  # Returning our result\n",
        "  return response.text"
      ],
      "metadata": {
        "id": "ZBMqOwIIGX3H"
      },
      "id": "ZBMqOwIIGX3H",
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "location=\"us-central1\"\n",
        "model = \"gemini-2.5-pro-preview-05-06\"\n",
        "\n",
        "apply_rag(project_id,location,model,generated_content_config,\"What is the ADS?\",3,0.85)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "x1zdAN9J6oDa",
        "outputId": "4fb23d2a-0d26-41b1-c29a-6beb38e3e43b"
      },
      "id": "x1zdAN9J6oDa",
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The ADS stands for the Alaska Department of Snow. We are the official organization in Alaska dedicated to managing and providing information about snow. This includes things like snowpack monitoring, avalanche safety programs, and public advisories related to snow conditions.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## UNIT TESTS OF AGENT FUNCTIONALITY"
      ],
      "metadata": {
        "id": "aMqSBK5s7bX3"
      },
      "id": "aMqSBK5s7bX3"
    },
    {
      "cell_type": "code",
      "source": [
        "def test_rag_theme():\n",
        "\n",
        "  # Boolean we will assess our outputs against\n",
        "  passed = True\n",
        "\n",
        "  location=\"us-central1\"\n",
        "  model = \"gemini-2.5-pro-preview-05-06\"\n",
        "  project_id =\"qwiklabs-gcp-02-cf6490c204fb\"\n",
        "\n",
        "  question_list = [(\"What is the ADS?\",\"the Alaska Department of Snow\")]\n",
        "\n",
        "  for item in question_list:\n",
        "    question = item[0]\n",
        "    template_answer = item[1]\n",
        "\n",
        "    gen_ai_answer = apply_rag(project_id,location,model,generated_content_config,question,3,0.85)\n",
        "\n",
        "    check_question = f\"\"\"\n",
        "    Are these responses covering the same topics? Answer with a yes or no\n",
        "\n",
        "    response1: {template_answer}\n",
        "    response2: {gen_ai_answer}\n",
        "    \"\"\"\n",
        "\n",
        "    check_client = genai.Client(\n",
        "      vertexai=True,\n",
        "      project=project_id,\n",
        "      location=location\n",
        "    )\n",
        "\n",
        "    checker = check_client.models.generate_content(model=model, contents=check_question)\n",
        "\n",
        "    if \"yes\" not in checker.text.lower():\n",
        "      print(gen_ai_answer)\n",
        "      print(\"------\")\n",
        "      print(template_answer)\n",
        "      passed = False\n",
        "\n",
        "    assert passed == True\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "KZCqGeBSXJ8U"
      },
      "id": "KZCqGeBSXJ8U",
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytest\n",
        "import ipytest\n",
        "ipytest.autoconfig()\n",
        "ipytest.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNYYQrRAZI7J",
        "outputId": "ba80019b-60df-47a7-e482-4d42e037e8a2"
      },
      "id": "GNYYQrRAZI7J",
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m.\u001b[0m\u001b[33m                                                                                            [100%]\u001b[0m\n",
            "\u001b[33m========================================= warnings summary =========================================\u001b[0m\n",
            "../usr/local/lib/python3.10/dist-packages/_pytest/config/__init__.py:1277\n",
            "  /usr/local/lib/python3.10/dist-packages/_pytest/config/__init__.py:1277: PytestAssertRewriteWarning: Module already imported so cannot be rewritten: anyio\n",
            "    self._mark_plugins_for_rewrite(hook)\n",
            "\n",
            "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
            "\u001b[33m\u001b[32m1 passed\u001b[0m, \u001b[33m\u001b[1m1 warning\u001b[0m\u001b[33m in 10.65s\u001b[0m\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<ExitCode.OK: 0>"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TESTS WITH GOOGLE EVALUATION SERVICE API"
      ],
      "metadata": {
        "id": "rUFJeGl-aLKZ"
      },
      "id": "rUFJeGl-aLKZ"
    },
    {
      "cell_type": "code",
      "source": [
        "project_id =\"qwiklabs-gcp-02-cf6490c204fb\"\n",
        "location=\"us-central1\"\n",
        "model = \"gemini-2.5-pro-preview-05-06\"\n",
        "similarity_score = 0.85\n",
        "k = 3\n",
        "\n",
        "contexts = [\"What is the ADS?\",\"Who is in chare of the ads?\"]\n",
        "\n",
        "base_prompt = \"\"\"\n",
        "Instructions: Answer the following question .\n",
        "\n",
        "Question: {}\n",
        "\"\"\"\n",
        "\n",
        "full_prompts = [base_prompt.format(i) for i in contexts]\n",
        "content = [apply_rag(project_id,location,model,generated_content_config,text,k,similarity_score) for text in contexts]\n",
        "\n",
        "eval_dataset = pd.DataFrame(\n",
        "{\n",
        "\"response\": content,\n",
        "\"context\": full_prompts,\n",
        "\"instruction\":full_prompts\n",
        "}\n",
        ")"
      ],
      "metadata": {
        "id": "4pAzqsyOZ0RE"
      },
      "id": "4pAzqsyOZ0RE",
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "AEDFChMDcPIO",
        "outputId": "047aa9c7-e95f-4dad-9693-ce8f572da0f7"
      },
      "id": "AEDFChMDcPIO",
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            response  \\\n",
              "0  The ADS stands for the Alaska Department of Sn...   \n",
              "1  The provided context does not specify who is i...   \n",
              "\n",
              "                                             context  \\\n",
              "0  \\nInstructions: Answer the following question ...   \n",
              "1  \\nInstructions: Answer the following question ...   \n",
              "\n",
              "                                         instruction  \n",
              "0  \\nInstructions: Answer the following question ...  \n",
              "1  \\nInstructions: Answer the following question ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06fa6b62-7059-4b29-a9a5-a016bb196dfb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>response</th>\n",
              "      <th>context</th>\n",
              "      <th>instruction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The ADS stands for the Alaska Department of Sn...</td>\n",
              "      <td>\\nInstructions: Answer the following question ...</td>\n",
              "      <td>\\nInstructions: Answer the following question ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The provided context does not specify who is i...</td>\n",
              "      <td>\\nInstructions: Answer the following question ...</td>\n",
              "      <td>\\nInstructions: Answer the following question ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06fa6b62-7059-4b29-a9a5-a016bb196dfb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-06fa6b62-7059-4b29-a9a5-a016bb196dfb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-06fa6b62-7059-4b29-a9a5-a016bb196dfb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0170dcaf-2240-4336-9c1f-5afd62615533\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0170dcaf-2240-4336-9c1f-5afd62615533')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0170dcaf-2240-4336-9c1f-5afd62615533 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "eval_dataset",
              "summary": "{\n  \"name\": \"eval_dataset\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"The provided context does not specify who is in overall charge of the ADS (Alaska Department of Snow). However, it does mention that Janet Kirk is the CFO, appointed in 2022, and she oversees all financial operations, including cost management and budget forecasting.\",\n          \"The ADS stands for the Alaska Department of Snow. We are a (fictional) government agency dedicated to managing all aspects of snow in Alaska. This includes snow removal, avalanche control, promoting snow-related tourism, and researching the impact of snow on the Alaskan environment and communities.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\nInstructions: Answer the following question .\\n    \\nQuestion: Who is in chare of the ads?\\n\",\n          \"\\nInstructions: Answer the following question .\\n    \\nQuestion: What is the ADS?\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"instruction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\nInstructions: Answer the following question .\\n    \\nQuestion: Who is in chare of the ads?\\n\",\n          \"\\nInstructions: Answer the following question .\\n    \\nQuestion: What is the ADS?\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "from vertexai.evaluation import (\n",
        "    MetricPromptTemplateExamples,\n",
        "    EvalTask,\n",
        "    PairwiseMetric,\n",
        "    PairwiseMetricPromptTemplate,\n",
        "    PointwiseMetric,\n",
        "    PointwiseMetricPromptTemplate\n",
        ")\n",
        "import vertexai\n",
        "\n",
        "eval_classify_users = EvalTask(\n",
        "    dataset=eval_dataset,\n",
        "    metrics=[MetricPromptTemplateExamples.Pointwise.FLUENCY,\n",
        "        MetricPromptTemplateExamples.Pointwise.VERBOSITY]\n",
        ")\n",
        "\n",
        "prompt_template = (\n",
        "    \"Instruction: {instruction}\\n\"\n",
        "    \"context: {context}\\n\"\n",
        "    \"response: {response}\"\n",
        ")\n",
        "result = eval_classify_users.evaluate(prompt_template=prompt_template)\n",
        "\n",
        "result.summary_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PS_6fOsycSIk",
        "outputId": "5815f6ba-5f67-49ef-e732-9774fbdbf231"
      },
      "id": "PS_6fOsycSIk",
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:vertexai.evaluation._evaluation:Assembling prompts from the `prompt_template`. The `prompt` column in the `EvalResult.metrics_table` has the assembled prompts used for model response generation.\n",
            "INFO:vertexai.evaluation._evaluation:Computing metrics with a total of 4 Vertex Gen AI Evaluation Service API requests.\n",
            "100%|██████████| 4/4 [00:03<00:00,  1.05it/s]\n",
            "INFO:vertexai.evaluation._evaluation:All 4 metric requests are successfully computed.\n",
            "INFO:vertexai.evaluation._evaluation:Evaluation Took:3.8154398859996945 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'row_count': 2,\n",
              " 'fluency/mean': 5.0,\n",
              " 'fluency/std': 0.0,\n",
              " 'verbosity/mean': 0.0,\n",
              " 'verbosity/std': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BRINGING EVERYTHING TOGETHER"
      ],
      "metadata": {
        "id": "PmaUiI98tVvl"
      },
      "id": "PmaUiI98tVvl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now create a function, apply_agent(), that will either provide information about Alaska's current weather or answers about the ADS. This is the function that will be hosted on the website."
      ],
      "metadata": {
        "id": "O5jcR4hKtZ7f"
      },
      "id": "O5jcR4hKtZ7f"
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_agent(user_input, config):\n",
        "\n",
        "  # Setting our configuration\n",
        "  project_id =\"qwiklabs-gcp-02-cf6490c204fb\"\n",
        "  location=\"us-central1\"\n",
        "  model = \"gemini-2.5-pro-preview-05-06\"\n",
        "  similarity_score = 0.85\n",
        "  k = 3\n",
        "\n",
        "  # We leverage Gemini to do an initial screen of whether the user is asking about snowfall\n",
        "  snowfall = False\n",
        "\n",
        "  screening_client = genai.Client(\n",
        "      vertexai=True,\n",
        "      project=project_id,\n",
        "      location=location\n",
        "  )\n",
        "\n",
        "  screening_question = f\"\"\"\n",
        "  Is the following question about how much snowfall is expected in Alaska? Answer with a yes or no\n",
        "\n",
        "  Question:\n",
        "  {user_input}\n",
        "  \"\"\"\n",
        "\n",
        "  screening_response = screening_client.models.generate_content(model=model, contents=screening_question)\n",
        "\n",
        "  if \"yes\" in screening_response.text.lower():\n",
        "    snowfall = True\n",
        "\n",
        "  # Apply the get_snowfall_info() if the question is about snowfall\n",
        "  if snowfall:\n",
        "    return get_snowfall_info()\n",
        "\n",
        "  # Use our RAG setup in all other instances\n",
        "  return apply_rag(project_id, location, model, config, user_input, k, similarity_score)"
      ],
      "metadata": {
        "id": "tPbtnWRPtqbD"
      },
      "id": "tPbtnWRPtqbD",
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now test out our finalised function that will be applied onto the website. As per the below, we can see that the model responds only to questions that it should (ie. snowfall and ADS details)"
      ],
      "metadata": {
        "id": "hIia8SVK6odZ"
      },
      "id": "hIia8SVK6odZ"
    },
    {
      "cell_type": "code",
      "source": [
        "apply_agent(\"What is the ADS?\", generated_content_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Dy4PtuGfv57R",
        "outputId": "a61347e7-1939-4fd9-e772-dd31cb3710eb"
      },
      "id": "Dy4PtuGfv57R",
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The ADS stands for the Alaska Department of Snow. We are a (fictional) government agency dedicated to managing snow-related resources, safety, and research in Alaska.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "apply_agent(\"How much snow will be in Alaska today?\", generated_content_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "lqggVSQ4wEHH",
        "outputId": "7bda8efd-427a-4f1b-aaaf-9081f62be25a"
      },
      "id": "lqggVSQ4wEHH",
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'There is no snow expected in Anchorage, AK today. The forecast is mostly sunny with a high near 52 degrees Fahrenheit.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "apply_agent(\"How much wood could a woodchuck chuck if a woodchuck could chuck wood?\", generated_content_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "iVU_9Sb9wM-x",
        "outputId": "feadd4f8-523f-40b6-8180-35b023391e78"
      },
      "id": "iVU_9Sb9wM-x",
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Sorry, I can't answer that question.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CREATING A WEBSITE TO HOST THIS INFO"
      ],
      "metadata": {
        "id": "zF7YeMo1dvXB"
      },
      "id": "zF7YeMo1dvXB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we attempt to use Dash as a proxy for a website"
      ],
      "metadata": {
        "id": "GxFEkel84PDp"
      },
      "id": "GxFEkel84PDp"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dash\n",
        "!pip install dash-core-components\n",
        "!pip install dash-html-components\n",
        "!pip install jupyter-dash"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7zdytytd4rG",
        "outputId": "309e894b-5f04-45e0-aacf-4914875c8df3"
      },
      "id": "C7zdytytd4rG",
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dash in /usr/local/lib/python3.10/dist-packages (3.0.4)\n",
            "Requirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash) (3.0.3)\n",
            "Requirement already satisfied: Werkzeug<3.1 in /usr/local/lib/python3.10/dist-packages (from dash) (3.0.6)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash) (5.24.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from dash) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from dash) (4.12.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dash) (2.32.3)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.10/dist-packages (from dash) (1.3.4)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from dash) (69.5.1)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash) (1.9.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash) (24.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from Werkzeug<3.1->dash) (3.0.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->dash) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dash) (2024.12.14)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from retrying->dash) (1.17.0)\n",
            "Requirement already satisfied: dash-core-components in /usr/local/lib/python3.10/dist-packages (2.0.0)\n",
            "Requirement already satisfied: dash-html-components in /usr/local/lib/python3.10/dist-packages (2.0.0)\n",
            "Requirement already satisfied: jupyter-dash in /usr/local/lib/python3.10/dist-packages (0.4.2)\n",
            "Requirement already satisfied: dash in /usr/local/lib/python3.10/dist-packages (from jupyter-dash) (3.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from jupyter-dash) (2.32.3)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from jupyter-dash) (3.0.3)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.10/dist-packages (from jupyter-dash) (1.3.4)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from jupyter-dash) (7.34.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyter-dash) (5.5.6)\n",
            "Requirement already satisfied: ansi2html in /usr/local/lib/python3.10/dist-packages (from jupyter-dash) (1.9.2)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from jupyter-dash) (1.6.0)\n",
            "Requirement already satisfied: Werkzeug<3.1 in /usr/local/lib/python3.10/dist-packages (from dash->jupyter-dash) (3.0.6)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash->jupyter-dash) (5.24.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from dash->jupyter-dash) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from dash->jupyter-dash) (4.12.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from dash->jupyter-dash) (69.5.1)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from flask->jupyter-dash) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from flask->jupyter-dash) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from flask->jupyter-dash) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from flask->jupyter-dash) (1.9.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter-dash) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter-dash) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter-dash) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter-dash) (6.3.3)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->jupyter-dash) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->jupyter-dash) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->jupyter-dash) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->jupyter-dash) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->jupyter-dash) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->jupyter-dash) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->jupyter-dash) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->jupyter-dash) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->jupyter-dash) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->jupyter-dash) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->jupyter-dash) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->jupyter-dash) (2024.12.14)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from retrying->jupyter-dash) (1.17.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->jupyter-dash) (0.8.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->flask->jupyter-dash) (3.0.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->jupyter-dash) (0.7.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash->jupyter-dash) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash->jupyter-dash) (24.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->jupyter-dash) (0.2.13)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->dash->jupyter-dash) (3.21.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->jupyter-dash) (5.7.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->jupyter-dash) (24.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->jupyter-dash) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel->jupyter-dash) (4.3.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing some base python packages\n",
        "import sys\n",
        "import subprocess\n",
        "import itertools\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "import dash\n",
        "import dash_core_components as dcc\n",
        "import dash_html_components as html\n",
        "from dash.dependencies import Input, Output, State\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.cloud import bigquery\n",
        "from jupyter_dash import JupyterDash\n"
      ],
      "metadata": {
        "id": "Wz1rqlqaduLt"
      },
      "id": "Wz1rqlqaduLt",
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app = dash.Dash()\n",
        "\n",
        "# Requires Dash 2.17.0 or later\n",
        "app.layout = html.Div(id = \"main_div\", children=[\n",
        "    html.H4(\"Enter Your Question Here\"),\n",
        "    dcc.Textarea(\n",
        "        id=\"user_prompt\",\n",
        "        value=\"prompt specified by the user\"\n",
        "    ),\n",
        "    html.Br(),\n",
        "    html.H4(\"Gen AI Response\"),\n",
        "    dcc.Textarea(\n",
        "        id=\"genai_response\",\n",
        "        value=\"Gen AI Response\"\n",
        "    ),\n",
        "    html.Br(),\n",
        "     html.Button('Submit Question', id='submit-to-genai', n_clicks=0),\n",
        "    ]\n",
        ")\n",
        "\n",
        "@app.callback(\n",
        "   Output(\"genai-response\",\"value\"),\n",
        "   Input(\"submit-to-gen-ai\",\"n_clicks\"),\n",
        "   State(\"user-story\",\"value\")\n",
        ")\n",
        "def genAIGenerate(clicks,query):\n",
        "  if clicks is not None and clicks > 0:\n",
        "    response = apply_agent(query, generated_content_config)\n",
        "  return response\n",
        "\n",
        "app.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "id": "fHhEo4uNfYid",
        "outputId": "3066f8d2-b497-48f4-8493-41a88255a3f3"
      },
      "id": "fHhEo4uNfYid",
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = new URL(path, url).toString();\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    iframe.allow = [\n",
              "        'accelerometer',\n",
              "        'autoplay',\n",
              "        'camera',\n",
              "        'clipboard-read',\n",
              "        'clipboard-write',\n",
              "        'gyroscope',\n",
              "        'magnetometer',\n",
              "        'microphone',\n",
              "        'serial',\n",
              "        'usb',\n",
              "        'xr-spatial-tracking',\n",
              "    ].join('; ');\n",
              "    element.appendChild(iframe);\n",
              "  })(8050, \"/\", \"100%\", 650, false, window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sKqvf3YMDzgM"
      },
      "id": "sKqvf3YMDzgM",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "student-02-76f58729f297 (May 13, 2025, 2:48:19 PM)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}